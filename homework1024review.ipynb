{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1024\n",
    "\n",
    "In class, we took a closer look at Berkeley's 311 data. Just like last week, I'd like you to create a similar Jupyter notebook using Oakland's data (that you cleaned up for homework). I did not create a homework notebook for you â€” you will create your own and upload it here.\n",
    "\n",
    "You can copy a lot of the code we used in class. You'll be graded with the following rubric:\n",
    "\n",
    "- You'll get 10 points total for documentation. You should describe what you're doing with your code using Markdown cells within your Jupyter notebook. Tell me what looks interesting or doesn't look right about the Oakland 311 data.\n",
    "- You'll get 10 points total for using (correctly) as many methods as we learned during lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import previously cleaned CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311 = pd.read_csv(\n",
    "    'oakland_311_cleaned.csv', \n",
    "    dtype={\n",
    "        'REQUESTID': object\n",
    "    },\n",
    "    parse_dates=['DATETIMEINIT', 'DATETIMECLOSED']\n",
    ")\n",
    "oakland_311.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timedelta\n",
    "oakland_311['ELAPSED_TIME'] = pd.to_timedelta(oakland_311['ELAPSED_TIME']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLL 1: When do you use Markdown vs # comments? Answer at [pollev.com/soooh](https://pollev.com/soooh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311['DATETIMEINIT'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of incidents by year\n",
    "\n",
    "I'm not going to filter by complete years because I want to show a chart by year-month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring i can use 'REQUESTID' to subset when aggregating for counts/medians/etc.\n",
    "assert len(oakland_311) == oakland_311['REQUESTID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking calls by year and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_by_year = oakland_311.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='A')]).count()[['REQUESTID']].reset_index()\n",
    "calls_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `REQUESTID` to `COUNT`\n",
    "calls_by_year.rename(columns={'REQUESTID': 'COUNT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart: Calls by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(calls_by_year).mark_bar().encode(\n",
    "    x='DATETIMEINIT:O', # try flipping O to T to see what happens\n",
    "    y='COUNT'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls_by_month = oakland_311.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='M')]).count()[['REQUESTID']].reset_index()\n",
    "\n",
    "# Rename `REQUESTID` to `COUNT`\n",
    "calls_by_month.rename(columns={'REQUESTID': 'COUNT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chart: Calls by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(calls_by_month).mark_bar().encode(\n",
    "    x='DATETIMEINIT:T',\n",
    "    y='COUNT'\n",
    ")\n",
    "\n",
    "# We'll learn how to add titles and other information during this lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incident types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311[['DESCRIPTION','REQCATEGORY']].drop_duplicates().sort_values(by=['REQCATEGORY']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oakland_311['REQCATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POLL 2: What are you noticing here? Answer at [pollev.com/soooh](https://pollev.com/soooh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at illegal dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps = oakland_311[oakland_311['REQCATEGORY'] == 'ILLDUMP'].reset_index(drop=True)\n",
    "illegal_dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps_by_month = illegal_dumps.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='M')]).count()[['REQUESTID']].reset_index()\n",
    "illegal_dumps_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps_by_month.columns = ['DATETIMEINIT', 'COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(illegal_dumps_by_month).mark_bar().encode(\n",
    "    x='DATETIMEINIT:T',\n",
    "    y='COUNT'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps['ELAPSED_TIME'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From mid-2010 to today, it's typically taken about 2-3 days to close Illegal Dump cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at illegal dumps more closely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to group up incidents by month based on the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dump_types_by_month = illegal_dumps.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='M'), 'DESCRIPTION']).count()[['REQUESTID']].reset_index()\n",
    "illegal_dump_types_by_month.columns = ['YEARMONTH', 'DESCRIPTION', 'COUNT']\n",
    "illegal_dump_types_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dump_types_by_month.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(illegal_dump_types_by_month).mark_bar().encode(\n",
    "    x='YEARMONTH',\n",
    "    y='COUNT',\n",
    "    color='DESCRIPTION',\n",
    "    tooltip='DESCRIPTION'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is super ugly but it's good for exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.S. Found a weird error in groupby aggregations!\n",
    "\n",
    "It looks like df.groupby() will include NaN fields when calculating medians, etc. So be careful. To be totally honest, I don't know what's going on here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found a solution for median() of timedeltas! Use `numeric_only=False`\n",
    "illegal_dumps_resolution_by_year = illegal_dumps.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='A')]).median(numeric_only=False)\n",
    "illegal_dumps_resolution_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are all those warnings?\n",
    "\n",
    "```\n",
    "FutureWarning: Dropping invalid columns in DataFrameGroupBy.median is deprecated. In a future version, a TypeError will be raised. Before calling .median, select only columns which should be valid for the function.\n",
    "  illegal_dumps_resolution_by_year = illegal_dumps.groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='A')]).median(numeric_only=False)\n",
    "```\n",
    "\n",
    "The warnings are for future versions of pandas. The software contributors are letting you know that they're going to change things up in the future. So don't get too used to this code!\n",
    "\n",
    "We can fix for this future warning (not required) by following some of the instructions. Specifically, \"Before calling .median, select only columns which should be valid for the function.\"\n",
    "\n",
    "Below, I'm going to subset the dataframe to `illegal_dumps[['DATETIMEINIT','ELAPSED_TIME']]`. Those are the only 2 columns I'm using. If I run this code, I won't get a warning (I also don't need to use `numeric_only=False` anymore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps_resolution_by_year = illegal_dumps[['DATETIMEINIT','ELAPSED_TIME']].groupby([pd.Grouper(key='DATETIMEINIT', axis=0, freq='A')]).median()\n",
    "\n",
    "illegal_dumps_resolution_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_dumps_2019 = illegal_dumps[\n",
    "    (illegal_dumps['DATETIMEINIT'] >= '2019-01-01') &    \n",
    "    (illegal_dumps['DATETIMEINIT'] <  '2020-01-01')     \n",
    "].copy()\n",
    "illegal_dumps_2019['ELAPSED_TIME'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('j233-files-3.9.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb04f89b61a62c03d47bf47357bc88692aa1a75ad45736fa559ef9e95df90447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
